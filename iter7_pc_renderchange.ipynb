{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "import numpy as np\n", "import json\n", "import os\n", "import matplotlib.pyplot as plt\n", "from mpl_toolkits.mplot3d import Axes3D\n", "from matplotlib.animation import FuncAnimation\n", "import torch\n", "from pythonopenpose import pyopenpose as op\n", "import matplotlib.patches as mpatches\n", "from matplotlib.figure import Figure\n", "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n", "import imageio"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define paths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["c233_path = r'C:\\Users\\aksh0\\Desktop\\Hackenza\\Quidich-HACKATHON-25\\233_im'\n", "c235_path = r'C:\\Users\\aksh0\\Desktop\\Hackenza\\Quidich-HACKATHON-25\\235_im'\n", "intrinsic_path = r'C:\\Users\\aksh0\\Desktop\\Hackenza\\Quidich-HACKATHON-25\\intrinsic.json'\n", "extrinsic_path = r'C:\\Users\\aksh0\\Desktop\\Hackenza\\Quidich-HACKATHON-25\\extrinsic.json'\n", "output_dir = r'C:\\Users\\aksh0\\Desktop\\Hackenza\\Quidich-HACKATHON-25\\processed_frames'\n", "os.makedirs(output_dir, exist_ok=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load intrinsic and extrinsic data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with open(intrinsic_path, 'r') as f:\n", "    intrinsic_data = json.load(f)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with open(extrinsic_path, 'r') as f:\n", "    extrinsic_data = json.load(f)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extract camera matrices and distortion coefficients"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["K1 = np.array(intrinsic_data['C233']['camera_matrix'])\n", "D1 = np.array(intrinsic_data['C233']['distortion_coefficients'])\n", "K2 = np.array(intrinsic_data['C235']['camera_matrix'])\n", "D2 = np.array(intrinsic_data['C235']['distortion_coefficients'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extract rotation and translation matrices"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["R1 = cv2.Rodrigues(np.array(extrinsic_data['rotation_vectors']['C233']))[0]\n", "T1 = np.array(extrinsic_data['translation_vectors']['C233']).reshape(3, 1)\n", "R2 = cv2.Rodrigues(np.array(extrinsic_data['rotation_vectors']['C235']))[0]\n", "T2 = np.array(extrinsic_data['translation_vectors']['C235']).reshape(3, 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute projection matrices"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["P1 = K1 @ np.hstack((R1, T1))\n", "P2 = K2 @ np.hstack((R2, T2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize OpenPose"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["params = {\n", "    \"model_folder\": \"models/\",\n", "    \"model_pose\": \"BODY_25\",\n", "    \"net_resolution\": \"656x368\",\n", "    \"number_people_max\": 1,\n", "    \"keypoint_scale\": 3\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Starting OpenPose"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["opWrapper = op.WrapperPython()\n", "opWrapper.configure(params)\n", "opWrapper.start()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define body parts by their index in BODY_25 model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["BODY_PARTS = {\n", "    \"Head\": [0, 1, 2, 3, 4, 15, 16, 17, 18],  # Nose, Eyes, Ears\n", "    \"Torso\": [1, 8, 5, 2, 12, 9, 1],  # Neck, Mid-hip, Shoulders, Hips\n", "    \"LeftArm\": [5, 6, 7],  # Left Shoulder, Elbow, Wrist\n", "    \"RightArm\": [2, 3, 4],  # Right Shoulder, Elbow, Wrist\n", "    \"LeftLeg\": [12, 13, 14],  # Left Hip, Knee, Ankle\n", "    \"RightLeg\": [9, 10, 11]  # Right Hip, Knee, Ankle\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define color for each body part"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["COLORS = {\n", "    \"Head\": (255, 255, 0),       # Yellow\n", "    \"Torso\": (0, 0, 255),        # Blue\n", "    \"LeftArm\": (0, 255, 0),      # Green\n", "    \"RightArm\": (0, 255, 0),     # Green\n", "    \"LeftLeg\": (255, 0, 0),      # Red\n", "    \"RightLeg\": (255, 0, 0)      # Red\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3D visualization connections"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SKELETON_CONNECTIONS_3D = {\n", "    \"Head\": [(0, 1), (1, 2), (1, 5), (2, 3), (3, 4), (5, 6), (6, 7), (1, 8), (1, 8), (15, 17), (16, 18)],\n", "    \"Torso\": [(1, 8), (8, 9), (8, 12), (1, 2), (1, 5), (2, 9), (5, 12)],\n", "    \"LeftArm\": [(5, 6), (6, 7)],\n", "    \"RightArm\": [(2, 3), (3, 4)],\n", "    \"LeftLeg\": [(12, 13), (13, 14)],\n", "    \"RightLeg\": [(9, 10), (10, 11)]\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function to triangulate a point between two camera views"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def triangulate_point(P1, P2, point1, point2):\n", "    A = np.array([\n", "        point1[0] * P1[2] - P1[0],\n", "        point1[1] * P1[2] - P1[1],\n", "        point2[0] * P2[2] - P2[0],\n", "        point2[1] * P2[2] - P2[1]\n", "    ])\n", "    _, _, V = np.linalg.svd(A)\n", "    X = V[-1]\n", "    return X[:3] / X[3]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function to draw skeletal structure on 2D images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def draw_skeleton_2d(image, keypoints, threshold=0.5):\n", "    # Draw lines for each body part\n", "    for part_name, indices in BODY_PARTS.items():\n", "        color = COLORS[part_name]\n", "        # Connect consecutive points in each body part\n", "        for i in range(len(indices) - 1):\n", "            idx1, idx2 = indices[i], indices[i + 1]\n", "            if keypoints[idx1, 2] > threshold and keypoints[idx2, 2] > threshold:\n", "                pt1 = (int(keypoints[idx1, 0]), int(keypoints[idx1, 1]))\n", "                pt2 = (int(keypoints[idx2, 0]), int(keypoints[idx2, 1]))\n", "                cv2.line(image, pt1, pt2, color, 2)\n", "        \n", "        # Draw keypoints\n", "        for idx in indices:\n", "            if keypoints[idx, 2] > threshold:\n", "                cv2.circle(image, (int(keypoints[idx, 0]), int(keypoints[idx, 1])), \n", "                           3, color, -1)\n", "    \n", "    return image"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Process a single frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_frame(frame_number):\n", "    # Construct file names\n", "    file1 = f\"HPUP_033_1_1_1_L_CAM-05_{frame_number:07d}.jpeg\"\n", "    file2 = f\"HPUP_033_1_1_1_L_CAM-02_{frame_number:07d}.jpeg\"\n\n", "    # Read frames from both cameras\n", "    frame1 = cv2.imread(os.path.join(c233_path, file1))\n", "    frame2 = cv2.imread(os.path.join(c235_path, file2))\n", "    if frame1 is None or frame2 is None:\n", "        print(f\"Frame {frame_number} missing in one of the cameras.\")\n", "        return None\n\n", "    # Process with OpenPose\n", "    datum1 = op.Datum()\n", "    datum2 = op.Datum()\n", "    \n", "    datum1.cvInputData = frame1\n", "    datum2.cvInputData = frame2\n", "    \n", "    opWrapper.emplaceAndPop(op.VectorDatum([datum1]))\n", "    opWrapper.emplaceAndPop(op.VectorDatum([datum2]))\n", "    \n", "    # Check if any poses were detected\n", "    if datum1.poseKeypoints is None or datum2.poseKeypoints is None:\n", "        print(f\"No poses detected in frame {frame_number}\")\n", "        return None\n", "    \n", "    if len(datum1.poseKeypoints) == 0 or len(datum2.poseKeypoints) == 0:\n", "        print(f\"No poses detected in frame {frame_number}\")\n", "        return None\n", "    \n", "    # Get the first person's keypoints\n", "    keypoints1 = datum1.poseKeypoints[0]\n", "    keypoints2 = datum2.poseKeypoints[0]\n", "    \n", "    # Draw skeletons on 2D images\n", "    frame1_with_skeleton = draw_skeleton_2d(frame1.copy(), keypoints1)\n", "    frame2_with_skeleton = draw_skeleton_2d(frame2.copy(), keypoints2)\n", "    \n", "    # Save processed frames\n", "    cv2.imwrite(os.path.join(output_dir, f\"cam233_frame_{frame_number}.jpg\"), frame1_with_skeleton)\n", "    cv2.imwrite(os.path.join(output_dir, f\"cam235_frame_{frame_number}.jpg\"), frame2_with_skeleton)\n", "    \n", "    # Initialize 3D points list and body part labels\n", "    points_3d = []\n", "    landmark_types = []\n", "    \n", "    # Triangulate all keypoints\n", "    for i in range(keypoints1.shape[0]):\n", "        # Check confidence threshold\n", "        if keypoints1[i, 2] > 0.5 and keypoints2[i, 2] > 0.5:\n", "            point1 = keypoints1[i, :2]\n", "            point2 = keypoints2[i, :2]\n", "            \n", "            # Triangulate 3D point\n", "            point_3d = triangulate_point(P1, P2, point1, point2)\n", "            points_3d.append(point_3d)\n", "            \n", "            # Determine which body part this keypoint belongs to\n", "            part_type = \"Other\"\n", "            for part_name, indices in BODY_PARTS.items():\n", "                if i in indices:\n", "                    part_type = part_name\n", "                    break\n", "            \n", "            landmark_types.append(part_type)\n", "        else:\n", "            # Add a placeholder for low confidence points\n", "            points_3d.append(np.array([0, 0, 0]))\n", "            landmark_types.append(\"Low Confidence\")\n", "    \n", "    return np.array(points_3d), landmark_types"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Process all frames"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Starting frame processing...\")\n", "all_3d_points = []\n", "all_landmark_types = []\n", "frame_range = range(350, 507, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for frame_number in frame_range:\n", "    if frame_number % 10 == 0:\n", "        print(f\"Processing frame {frame_number}\")\n", "    \n", "    result = process_frame(frame_number)\n", "    if result is not None:\n", "        points_3d, landmark_types = result\n", "        all_3d_points.append(points_3d)\n", "        all_landmark_types.append(landmark_types)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Processed {len(all_3d_points)} frames successfully\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function to draw skeleton in 3D plot with improved rendering"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def draw_skeleton_3d(ax, points, landmark_types):\n", "    # Plot connections between keypoints for each body part\n", "    for part_name, connections in SKELETON_CONNECTIONS_3D.items():\n", "        color_map = {\"Head\": 'yellow', \"Torso\": 'blue', \"LeftArm\": 'green', \n", "                    \"RightArm\": 'green', \"LeftLeg\": 'red', \"RightLeg\": 'red'}\n", "        \n", "        for connection in connections:\n", "            idx1, idx2 = connection\n", "            if idx1 < len(points) and idx2 < len(points):\n", "                # Check if points are valid (not placeholder zeros)\n", "                if not np.all(points[idx1] == 0) and not np.all(points[idx2] == 0):\n", "                    ax.plot([points[idx1][0], points[idx2][0]],\n", "                           [points[idx1][1], points[idx2][1]],\n", "                           [points[idx1][2], points[idx2][2]],\n", "                           color=color_map[part_name], linewidth=3, alpha=0.7)\n", "    \n", "    # Plot keypoints with colors based on body part\n", "    for i, (point, part_type) in enumerate(zip(points, landmark_types)):\n", "        if part_type != \"Low Confidence\" and not np.all(point == 0):\n", "            color_map = {\"Head\": 'yellow', \"Torso\": 'blue', \"LeftArm\": 'green', \n", "                        \"RightArm\": 'green', \"LeftLeg\": 'red', \"RightLeg\": 'red', \"Other\": 'gray'}\n", "            \n", "            ax.scatter(point[0], point[1], point[2], \n", "                      color=color_map.get(part_type, 'gray'), \n", "                      s=30, edgecolors='black', alpha=0.8)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a higher quality 3D animation with improved renderer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_animation():\n", "    print(\"Creating 3D animation...\")\n", "    fig = plt.figure(figsize=(12, 12), dpi=150)\n", "    canvas = FigureCanvas(fig)\n", "    ax = fig.add_subplot(111, projection='3d')\n", "    \n", "    # Set up the 3D plot style\n", "    ax.set_facecolor('whitesmoke')\n", "    fig.patch.set_facecolor('white')\n", "    \n", "    # Adjust the viewing angle for better perspective\n", "    ax.view_init(elev=20, azim=60)\n", "    \n", "    # Create empty frames list for animation\n", "    frames = []\n", "    \n", "    # Calculate bounds for consistent scaling\n", "    all_x = []\n", "    all_y = []\n", "    all_z = []\n", "    for points in all_3d_points:\n", "        valid_points = points[~np.all(points == 0, axis=1)]\n", "        if len(valid_points) > 0:\n", "            all_x.extend(valid_points[:, 0])\n", "            all_y.extend(valid_points[:, 1])\n", "            all_z.extend(valid_points[:, 2])\n", "    \n", "    x_range = [min(all_x), max(all_x)]\n", "    y_range = [min(all_y), max(all_y)]\n", "    z_range = [min(all_z), max(all_z)]\n", "    \n", "    # Buffer for better viewing\n", "    buffer = 0.1\n", "    x_range = [x_range[0] - buffer * (x_range[1] - x_range[0]), \n", "               x_range[1] + buffer * (x_range[1] - x_range[0])]\n", "    y_range = [y_range[0] - buffer * (y_range[1] - y_range[0]), \n", "               y_range[1] + buffer * (y_range[1] - y_range[0])]\n", "    z_range = [z_range[0] - buffer * (z_range[1] - z_range[0]), \n", "               z_range[1] + buffer * (z_range[1] - z_range[0])]\n", "    \n", "    for frame_idx in range(len(all_3d_points)):\n", "        if frame_idx % 10 == 0:\n", "            print(f\"Rendering frame {frame_idx + 350}\")\n", "        \n", "        ax.clear()\n", "        \n", "        # Set fixed axis limits for consistency\n", "        ax.set_xlim(x_range)\n", "        ax.set_ylim(y_range)\n", "        ax.set_zlim(z_range)\n", "        \n", "        # Setup axes\n", "        ax.set_xlabel('X', fontsize=14)\n", "        ax.set_ylabel('Y', fontsize=14)\n", "        ax.set_zlabel('Z', fontsize=14)\n", "        ax.set_title(f'3D Pose Estimation - Frame {frame_idx + 350}', fontsize=16)\n", "        \n", "        # Draw the skeleton\n", "        draw_skeleton_3d(ax, all_3d_points[frame_idx], all_landmark_types[frame_idx])\n", "        \n", "        # Add legend\n", "        head_patch = mpatches.Patch(color='yellow', label='Head')\n", "        torso_patch = mpatches.Patch(color='blue', label='Torso')\n", "        arm_patch = mpatches.Patch(color='green', label='Arms')\n", "        leg_patch = mpatches.Patch(color='red', label='Legs')\n", "        ax.legend(handles=[head_patch, torso_patch, arm_patch, leg_patch], \n", "                 loc='upper right', fontsize=12)\n", "        \n", "        # Render frame\n", "        fig.tight_layout()\n", "        canvas.draw()\n", "        \n", "        # Convert to image\n", "        img = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n", "        img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n", "        \n", "        frames.append(img)\n", "    \n", "    # Save the animation as high quality video\n", "    print(\"Saving animation...\")\n", "    imageio.mimsave(os.path.join(output_dir, '3d_pose_animation_improved.mp4'), \n", "                   frames, fps=10, quality=8)\n", "    \n", "    # Also save as gif for wider compatibility\n", "    imageio.mimsave(os.path.join(output_dir, '3d_pose_animation_improved.gif'), \n", "                   frames, fps=5)\n", "    \n", "    print(f\"Animation saved to {output_dir}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create still image visualization for single frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def visualize_single_frame():\n", "    if len(all_3d_points) == 0:\n", "        print(\"No frames processed successfully.\")\n", "        return\n", "    \n", "    # Create a high-quality figure for a single frame\n", "    fig = plt.figure(figsize=(12, 12), dpi=150)\n", "    ax = fig.add_subplot(111, projection='3d')\n", "    \n", "    # Set up the 3D plot style\n", "    ax.set_facecolor('whitesmoke')\n", "    fig.patch.set_facecolor('white')\n", "    \n", "    # Adjust the viewing angle for better perspective\n", "    ax.view_init(elev=20, azim=60)\n", "    \n", "    # Draw the first frame\n", "    draw_skeleton_3d(ax, all_3d_points[0], all_landmark_types[0])\n", "    \n", "    # Set axis labels and title\n", "    ax.set_xlabel('X', fontsize=14)\n", "    ax.set_ylabel('Y', fontsize=14)\n", "    ax.set_zlabel('Z', fontsize=14)\n", "    ax.set_title('3D Pose Estimation with Enhanced Rendering', fontsize=16)\n", "    \n", "    # Add legend\n", "    head_patch = mpatches.Patch(color='yellow', label='Head')\n", "    torso_patch = mpatches.Patch(color='blue', label='Torso')\n", "    arm_patch = mpatches.Patch(color='green', label='Arms')\n", "    leg_patch = mpatches.Patch(color='red', label='Legs')\n", "    ax.legend(handles=[head_patch, torso_patch, arm_patch, leg_patch], \n", "             loc='upper right', fontsize=12)\n", "    \n", "    # Save high-resolution image\n", "    plt.tight_layout()\n", "    plt.savefig(os.path.join(output_dir, '3d_pose_single_frame.png'), dpi=300)\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Run the visualization and animation functions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if len(all_3d_points) > 0:\n", "    print(\"Generating visualizations...\")\n", "    visualize_single_frame()\n", "    create_animation()\n", "    print(\"Processing complete!\")\n", "else:\n", "    print(\"No frames were successfully processed. Check your paths and OpenPose installation.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Clean up"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cv2.destroyAllWindows()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}